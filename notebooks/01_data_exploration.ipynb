{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from src.model.lit_module import LitModule\n",
    "from src.data.dataset import VideoLabelDataset\n",
    "import src.constants as const\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data.dataset import (VideoLabelDataset,\n",
    "                              VideoFolderPathToTensor,\n",
    "                              VideoResize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoLabelDataset(\n",
    "            const.LABELS_TABLE_QA_PATH,\n",
    "            img_transform=torchvision.transforms.Compose([\n",
    "                VideoFolderPathToTensor(),\n",
    "                VideoResize(const.IMG_SIZE)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=20, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos, questions, answers, hidden_states, vid_folder  = iter(dataloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imgs_folder_path</th>\n",
       "      <th>box_x</th>\n",
       "      <th>pipe_x</th>\n",
       "      <th>enemy_speed</th>\n",
       "      <th>mario_speed</th>\n",
       "      <th>answer_box</th>\n",
       "      <th>answer_pipe</th>\n",
       "      <th>answer_enemy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data/imgs_series/00001</td>\n",
       "      <td>0.156313</td>\n",
       "      <td>0.185930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.490709</td>\n",
       "      <td>2.426097</td>\n",
       "      <td>9.639865</td>\n",
       "      <td>3.860908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data/imgs_series/00002</td>\n",
       "      <td>0.214429</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>80.115156</td>\n",
       "      <td>2.708601</td>\n",
       "      <td>9.224222</td>\n",
       "      <td>2.239635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>data/imgs_series/00003</td>\n",
       "      <td>0.018036</td>\n",
       "      <td>0.130653</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>95.058088</td>\n",
       "      <td>1.251866</td>\n",
       "      <td>7.742634</td>\n",
       "      <td>2.034848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>data/imgs_series/00004</td>\n",
       "      <td>0.104208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>62.359386</td>\n",
       "      <td>2.597845</td>\n",
       "      <td>14.576795</td>\n",
       "      <td>3.623262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>data/imgs_series/00005</td>\n",
       "      <td>0.262525</td>\n",
       "      <td>0.396985</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>51.039479</td>\n",
       "      <td>4.721835</td>\n",
       "      <td>15.458622</td>\n",
       "      <td>4.774413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>data/imgs_series/00006</td>\n",
       "      <td>0.797595</td>\n",
       "      <td>0.477387</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>65.566828</td>\n",
       "      <td>7.747820</td>\n",
       "      <td>12.277550</td>\n",
       "      <td>2.780107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>data/imgs_series/00007</td>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>63.341972</td>\n",
       "      <td>2.036564</td>\n",
       "      <td>12.393046</td>\n",
       "      <td>3.026803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>data/imgs_series/00008</td>\n",
       "      <td>0.689379</td>\n",
       "      <td>0.095477</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>76.515466</td>\n",
       "      <td>5.933441</td>\n",
       "      <td>9.527486</td>\n",
       "      <td>3.282067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>data/imgs_series/00009</td>\n",
       "      <td>0.390782</td>\n",
       "      <td>0.206030</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>59.868291</td>\n",
       "      <td>5.094517</td>\n",
       "      <td>12.544203</td>\n",
       "      <td>6.156157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>data/imgs_series/00010</td>\n",
       "      <td>0.150301</td>\n",
       "      <td>0.366834</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>95.022940</td>\n",
       "      <td>1.946898</td>\n",
       "      <td>8.240116</td>\n",
       "      <td>1.832633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        imgs_folder_path     box_x    pipe_x  enemy_speed  \\\n",
       "0           0  data/imgs_series/00001  0.156313  0.185930     1.000000   \n",
       "1           1  data/imgs_series/00002  0.214429  0.145729     0.250000   \n",
       "2           2  data/imgs_series/00003  0.018036  0.130653     0.666667   \n",
       "3           3  data/imgs_series/00004  0.104208  1.000000     0.291667   \n",
       "4           4  data/imgs_series/00005  0.262525  0.396985     0.125000   \n",
       "5           5  data/imgs_series/00006  0.797595  0.477387     0.041667   \n",
       "6           6  data/imgs_series/00007  0.038076  0.376884     0.083333   \n",
       "7           7  data/imgs_series/00008  0.689379  0.095477     0.750000   \n",
       "8           8  data/imgs_series/00009  0.390782  0.206030     0.708333   \n",
       "9           9  data/imgs_series/00010  0.150301  0.366834     0.416667   \n",
       "\n",
       "   mario_speed  answer_box  answer_pipe  answer_enemy  \n",
       "0    77.490709    2.426097     9.639865      3.860908  \n",
       "1    80.115156    2.708601     9.224222      2.239635  \n",
       "2    95.058088    1.251866     7.742634      2.034848  \n",
       "3    62.359386    2.597845    14.576795      3.623262  \n",
       "4    51.039479    4.721835    15.458622      4.774413  \n",
       "5    65.566828    7.747820    12.277550      2.780107  \n",
       "6    63.341972    2.036564    12.393046      3.026803  \n",
       "7    76.515466    5.933441     9.527486      3.282067  \n",
       "8    59.868291    5.094517    12.544203      6.156157  \n",
       "9    95.022940    1.946898     8.240116      1.832633  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.constants' from '/Users/henrik/Documents/hsu/mario-communicating-agents/src/constants.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './lightning_logs/version_2/checkpoints/epoch=95-step=767.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModule.load_from_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoLabelDataset(\n",
    "            const.LABELS_TABLE_QA_PATH,\n",
    "            img_transform=torchvision.transforms.Compose([\n",
    "                VideoFolderPathToTensor(),\n",
    "                VideoResize(const.IMG_SIZE)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=10, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos, questions, answers, hidden_states, _  = iter(dataloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8450, 0.5448, 0.9398],\n",
       "        [0.1780, 0.5085, 0.1194],\n",
       "        [0.2152, 0.5859, 0.5385],\n",
       "        [0.7205, 0.5345, 0.5399],\n",
       "        [0.0955, 0.3855, 0.8686],\n",
       "        [0.1475, 0.6312, 0.9583],\n",
       "        [0.8030, 0.5446, 0.8962],\n",
       "        [0.5937, 0.5861, 0.6022],\n",
       "        [0.6369, 0.5447, 0.6521],\n",
       "        [0.4800, 0.4428, 0.6196]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.eval()(videos)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8956, 0.3618, 0.8750],\n",
       "        [0.2068, 0.9950, 0.1250],\n",
       "        [0.2169, 0.6080, 0.5417],\n",
       "        [0.6988, 0.5578, 0.5000],\n",
       "        [0.0482, 0.1709, 0.9167],\n",
       "        [0.0823, 0.5678, 0.9583],\n",
       "        [0.8293, 0.9246, 0.8750],\n",
       "        [0.5823, 0.0050, 0.5000],\n",
       "        [0.6506, 0.9899, 0.5417],\n",
       "        [0.4317, 0.1307, 0.5833]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2628, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss = torch.nn.MSELoss(reduction='sum')\n",
    "mse_hidden = mse_loss(predictions[0:2,:].type(torch.float32),\n",
    "                      hidden_states[0:2,:].type(torch.float32))\n",
    "mse_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73323.68388475002"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[543.4559, 996.8821,  37.2706],\n",
       "        [543.4633, 996.8958,  37.2711]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
